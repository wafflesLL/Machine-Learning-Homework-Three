{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f05b3f92-f83e-497b-ba34-1040b83580e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib64/python3.13/site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib64/python3.13/site-packages (0.24.1)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib64/python3.13/site-packages (3.10.7)\n",
      "Requirement already satisfied: torchinfo in ./.venv/lib64/python3.13/site-packages (1.8.0)\n",
      "Requirement already satisfied: torchviz in ./.venv/lib64/python3.13/site-packages (0.0.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib64/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in ./.venv/lib64/python3.13/site-packages (2.3.4)\n",
      "Requirement already satisfied: filelock in ./.venv/lib64/python3.13/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib64/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib64/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib64/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib64/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib64/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib64/python3.13/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib64/python3.13/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib64/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib64/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib64/python3.13/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib64/python3.13/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib64/python3.13/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib64/python3.13/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib64/python3.13/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib64/python3.13/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib64/python3.13/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib64/python3.13/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib64/python3.13/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib64/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib64/python3.13/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib64/python3.13/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.venv/lib64/python3.13/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib64/python3.13/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib64/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib64/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib64/python3.13/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib64/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib64/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib64/python3.13/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib64/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: graphviz in ./.venv/lib64/python3.13/site-packages (from torchviz) (0.21)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib64/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib64/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib64/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib64/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib64/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision matplotlib torchinfo torchviz pandas numpy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(45)\n",
    "np.random.seed(45)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af4ae7-ca02-4736-979e-7715ca0427a9",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dffcc074-f0a0-412a-977b-d6788d6f9c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_ori = pd.read_csv('titanic_data/train.csv')\n",
    "test_df_ori = pd.read_csv('titanic_data/test.csv')\n",
    "\n",
    "train_df = train_df_ori.copy()\n",
    "test_df = test_df_ori.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6176fcba-b356-4308-a9a0-51daef2ac5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.drop(['PassengerId', 'Name'], axis=1, inplace=True)\n",
    "test_df.drop(['Name'], axis=1, inplace=True)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31ca4a5f-f68d-4fba-92eb-1f6e407a58be",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_too_many = ['Cabin', 'Ticket']\n",
    "train_df.drop(missing_too_many, axis=1, inplace=True)\n",
    "test_df.drop(missing_too_many, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86949a2f-72e8-48d0-b3e4-9d0121c1d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE\n",
    "def imputer(df: pd.DataFrame, columns: list):\n",
    "    # find columns that contain nans and impute them with the median values\n",
    "    df_copy = df.copy()\n",
    "    for col in columns:\n",
    "        median = df_copy[col].median()\n",
    "        df_copy[col] = df_copy[col].fillna(median, inplace=False)\n",
    "    return df_copy\n",
    "\n",
    "def PandasOneHotEncodeNumpy(df: pd.DataFrame, columns: list):\n",
    "    df_copy = df.copy()\n",
    "    for i, col in enumerate(columns):\n",
    "        uniques = df_copy[col].unique()\n",
    "        uniques.sort() # to account for differing orders items occur in test vs train\n",
    "        for unique in uniques[1:]:\n",
    "            name = f\"{columns[i]}_{unique}\"\n",
    "            df_copy.insert(0, name, [0] * df_copy.shape[0], allow_duplicates=False)\n",
    "            uniqueMap = {f\"{unique}\":1}\n",
    "            df_copy[name] = df_copy[col].map(uniqueMap)\n",
    "            df_copy[name] = df_copy[name].fillna(0, inplace=False)\n",
    "    df_copy.drop(columns, axis=1, inplace=True)\n",
    "    col = df_copy.columns\n",
    "    return col, df_copy.to_numpy().astype(\"float32\")\n",
    "\n",
    "columns_train = ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "columns_test = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "train_df['Embarked'] = train_df['Embarked'].fillna('S', inplace=False)\n",
    "test_df['Embarked'] = test_df['Embarked'].fillna('S', inplace=False)\n",
    "\n",
    "train_df = imputer(train_df, columns_train)\n",
    "test_df = imputer(test_df, columns_test)\n",
    "\n",
    "columns = ['Sex', 'Embarked']\n",
    "# get all the unique values in the columns and \n",
    "train_col, train_df = PandasOneHotEncodeNumpy(train_df, columns)\n",
    "test_col, test_df = PandasOneHotEncodeNumpy(test_df, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34966099-828e-4061-8e07-7903d267726c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Embarked_S', 'Embarked_Q', 'Sex_male', 'PassengerId', 'Pclass', 'Age',\n",
       "       'SibSp', 'Parch', 'Fare'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb4eb2dc-4184-44ec-a2ca-e3105da4c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "# Standardization\n",
    "# min-max scaling\n",
    "def findI(key, cols):\n",
    "    for i, val in enumerate(cols):\n",
    "        if key == cols[i]:\n",
    "            return i\n",
    "\n",
    "def standardize(dp, cols_all, cols_target):\n",
    "    dp_copy = dp\n",
    "    for col in cols_target:\n",
    "        column = dp_copy[:,findI(col, cols_all)]\n",
    "        column = (column - column.min()) / (column.max() - column.min())\n",
    "        dp_copy[:,findI(col, cols_all)] = column\n",
    "    return dp_copy\n",
    "        \n",
    "\n",
    "\n",
    "train_df = standardize(train_df, train_col, ['Age', 'Fare'])\n",
    "test_df = standardize(test_df, test_col, ['Age', 'Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb795cd0-1a11-4c51-b8c8-2b90254a423c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Embarked_S', 'Embarked_Q', 'Sex_male', 'Survived', 'Pclass', 'Age',\n",
       "       'SibSp', 'Parch', 'Fare'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "373b7e19-50f0-4870-96d9-68d3c03fca3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Embarked_S', 'Embarked_Q', 'Sex_male', 'PassengerId', 'Pclass', 'Age',\n",
       "       'SibSp', 'Parch', 'Fare'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b2f864d-b45a-40f8-b81f-27324a60b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47d7ab03-f241-48d1-9d62-e906d020423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset:\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = torch.from_numpy(X_data)\n",
    "        self.y_data = torch.from_numpy(y_data)\n",
    "        self.n_samples = self.X_data.shape[0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9c9ac9d-6a62-436a-8032-dfad3a35e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_before = train_df[:, :3]\n",
    "X_after = train_df[:, 4:]\n",
    "X = np.hstack([X_before, X_after])\n",
    "y = train_df[:, 3]\n",
    "def split_set(X_all, y_all, split):\n",
    "    split_index = int(train_df.shape[0] * split)\n",
    "    X_val = X_all[:split_index]\n",
    "    y_val = y_all[:split_index]\n",
    "    X = X_all[split_index:]\n",
    "    y = y_all[split_index:]\n",
    "    return X_val, y_val, X, y\n",
    "\n",
    "X_val, y_val, X, y = split_set(X, y, .15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d011aecb-0bb3-4b5a-bd80-c40e13eadd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = TitanicDataset(X_val, y_val)\n",
    "train = TitanicDataset(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287487f1-7a26-4592-aff9-007cab658de0",
   "metadata": {},
   "source": [
    "# Building the Neural Network\n",
    "1. Build an N-Layer Multi-Layer Perceptron Model using PyTorch, with RELU activation in the hidden layers, Gradient Descent optimization, and a Cross-Entropy Loss. Name your neural network class `MLP_Network`.\n",
    "    * References:\n",
    "\t    1.  [A Quick Introduction to PyTorch (with a Hands-On Mini Project)](https://medium.com/ai-ml-interview-playbook/a-quick-introduction-to-pytorch-with-a-hands-on-mini-project-b58bd9220813)\n",
    "        2. [Building Multilayer Perceptron Models in PyTorch - MachineLearningMastery.com](https://machinelearningmastery.com/building-multilayer-perceptron-models-in-pytorch/)\n",
    "        3. [Building a PyTorch binary classification multi-layer perceptron from the ground up – Hutsons-hacks](https://hutsons-hacks.info/building-a-pytorch-binary-classification-multi-layer-perceptron-from-the-ground-up)\n",
    "        4. [Introduction to PyTorch — PyTorch Tutorials 2.9.0+cu128 documentation](https://docs.pytorch.org/tutorials/beginner/introyt/introyt1_tutorial.html)\n",
    "        5. Dr. Santos' collab code: [Google Colab](https://colab.research.google.com/drive/1FpzMOkUGtPQDljfS32uJLD_zz4wmQ6GF#scrollTo=843d9673)\n",
    "2. Recall that the sizes of the input and output layers—that is, the number of neurons in each layer—are determined by the input data and the number of classes in the application, respectively. However, you will need to select the sizes for the hidden layers. Experiment with different hidden layer sizes, making each subsequent layer half the size of the previous one.(i.e., $m^{[l]} = 2*m^{[l+1]}$).\n",
    "3. Hyperparameter search: The `MLP_Network`class should support different network depths and hidden layer sizes. You can perform the hyperparameter search manually or with the help of a tool like Optuna. You will train at least 36 different MLP models for the following hyperparameters:\n",
    "    1. Network depth 2x\n",
    "    2. Hidden layers sizes 2x\n",
    "    3. Learning rates 3x\n",
    "    4. Regularization 3x\n",
    "    5. Number of iterations: Based on your loss curves make a choice for the number of Gradient Descent iterations controlled at the epoch level with the variable `num_epochs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09f297c9-f1e1-48f3-8e2d-dffae7f5bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MLP_Network(nn.Module):\n",
    "    def __init__(self, hidden_sizes: List[int], num_classes: int, input_size: int):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        last_size = input_size\n",
    "\n",
    "        for hidden_size in hidden_sizes:\n",
    "            self.layers.append(nn.Linear(last_size, hidden_size))\n",
    "            self.layers.append(nn.ReLu())\n",
    "            last_size = hidden_size\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output = nn.Linear(last_size, num_classes)\n",
    "        self.depth = len(hidden_sizes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if x.dim() > 2:\n",
    "            x = x.reshape(-1, self.input_size)\n",
    "        \n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "\n",
    "        out = self.output(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2641030-fa5c-4b80-8c6d-0dfe505a007c",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f80bd8d-1efc-4f9f-8381-73ff20e02ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X.shape[0]\n",
    "hidden_sizes = []\n",
    "network_depth = len(hidden_sizes)\n",
    "learning_rates = []\n",
    "regularization = 'l1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7cfcdfdc-0dc7-4482-b7bb-abe2e50e5008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a79f135-54ba-4f68-85bc-8f324b6d1a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    output_loss = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterions(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        output_loss = running_loss / len(train_loader)\n",
    "\n",
    "    final_accuracy = calculate_accuracy(model, train_loader)\n",
    "    return outoput_loss, final_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "33426f09-bae6-4848-93d1-72505d78ebcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optuna' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective\u001b[39m(trial: \u001b[43moptuna\u001b[49m.Trial, train_loader, val_loader, input_size, num_classes):\n\u001b[32m      2\u001b[39m     depth = trial.suggest_categorical(\u001b[33m'\u001b[39m\u001b[33mdepth\u001b[39m\u001b[33m'\u001b[39m, [\u001b[32m2\u001b[39m, \u001b[32m4\u001b[39m])\n\u001b[32m      4\u001b[39m     hidden_layer_sizes = [\u001b[32m128\u001b[39m, \u001b[32m64\u001b[39m, \u001b[32m32\u001b[39m, \u001b[32m16\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'optuna' is not defined"
     ]
    }
   ],
   "source": [
    "def objective(trial: optuna.Trial, train_loader, val_loader, input_size, num_classes):\n",
    "    depth = trial.suggest_categorical('depth', [2, 4])\n",
    "\n",
    "    base_sizes = [128, 64, 32, 16]\n",
    "    hidden_layer_sizes = base_sizes[:depth]\n",
    "\n",
    "    lr = trial.suggest_categorical('lr', [0.1, 0.01, 0.001])\n",
    "    wd = trial.suggest_categorical('weight_decay', [0.0, 0.001, 0.01])\n",
    "\n",
    "    model = MLP_Network(\n",
    "        input_size=input_size,\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    train_model(model, train_loader, criterion, optimizer)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    final_val_losss = val_loss / len(val_loader)\n",
    "    \n",
    "    return final_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1368d402-ba89-46d1-bb32-73bf617cd9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_search():\n",
    "    train_loader, val_loader, INPUT_SIZE, NUM_CLASSES = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True),\n",
    "                                                        data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False),\n",
    "                                                        input_size,\n",
    "                                                        2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc0160f-64f6-4b69-862f-05162dcfb944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
